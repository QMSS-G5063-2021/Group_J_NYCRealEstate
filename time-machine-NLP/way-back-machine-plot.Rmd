---
title: "time-machine-word-cloud"
author: "yjw2106"
date: "4/10/2021"
output: html_document
---

## way-back-machine data

```{r error=TRUE, message=FALSE, warning=FALSE}
library(lubridate)
library(dplyr)
library(tm)
library(tidytext)
library(SnowballC)
library(ggplot2)
library(wordcloud)

df = read.csv("TimeMachine.csv")

df_clean = df %>%
  mutate(date = substr(date, 1, 8)) %>%
  mutate(date = ymd(date)) %>%
  mutate(year = year(date)) %>%
  select(-X)%>%
  mutate(clean_text = tolower(text)) %>%
  mutate(clean_text = removeNumbers(clean_text)) %>%
  mutate(clean_text = stripWhitespace(clean_text)) %>%
  mutate(clean_text = removeWords(clean_text, stopwords("en")))

# - function to create wordcloud based on year and neighborhood selected
draw.wordcloud = function(select_neighborhood, select_year) {
  cloud.year = df_clean %>%
    filter(neighborhood==select_neighborhood) %>%
    filter(year == select_year) %>%
    head(1) %>%
    select(year, clean_text)
  
  cloud.hist = df_clean %>%
    filter(neighborhood==select_neighborhood) %>%
    arrange(desc(-1*year)) %>%
    head(1) %>%
    select(year, clean_text)
  
  combined = c(cloud.year$clean_text, cloud.hist$clean_text)
  corpus = Corpus(VectorSource(combined))
  tdm = TermDocumentMatrix(corpus)
  tdm = as.matrix(tdm)
  colnames(tdm) = c(cloud.year$year, cloud.hist$year)
  
  # comparison cloud
  wordcloud = comparison.cloud(tdm, random.order=FALSE, 
                   colors = c("#FF0099", "#6600CC"), title.size=1.5, max.words=500)
  
  return(wordcloud)
  
}

draw.wordcloud(select_neighborhood = "Hamilton Heights", select_year = 2020)

```

# line graph of when it was first published and number of changes through time
# line graph of sentiment through time
# most used word by year
# most common words 2010 vs 2021
```{r, message=FALSE, warning=FALSE}

dark2 <- colorRampPalette(brewer.pal(8, "Dark2"))(10)

test = df_clean %>%
  group_by(year, neighborhood) %>%
  summarise(total = n())

ggplot(test, aes(year, total, color=neighborhood)) +
  geom_line(size=1.5)+
  gghighlight(neighborhood == "Chelsea")+
  scale_color_manual(values=dark2) + 
  labs(x = "Year", y="Total Number of Wikipedia Page Revisions",
       title="Number of Wikipedia Page Revisions by Year for Manhattan Neighborhoods") +
  theme_minimal()

```
```{r, message=FALSE, warning=FALSE}

dict = tidytext::sentiments
pos = dict %>% filter(sentiment == "positive") %>% select(word)
neg = dict %>% filter(sentiment == "negative") %>% select(word)

sentiment <- function(words=c("really great good stuff bad")){
  require(quanteda)
  tok <- quanteda::tokens(words)
  pos.count <- sum(tok[[1]]%in%pos[[1]])
  positive_words = cat("\n positive words:",tok[[1]][which(tok[[1]]%in%pos[[1]])],"\n")
  neg.count <- sum(tok[[1]]%in%neg[[1]])
  negative_words = cat("\n negative words:",tok[[1]][which(tok[[1]]%in%neg[[1]])],"\n")
  out <- (pos.count - neg.count)/(pos.count+neg.count)
  cat("\n Tone of Document:", out)
  
  out = ifelse(is.na(out), 0, out)
  return (out)
}

df_sentiment=df_clean
df_sentiment$sentiment = lapply(df_sentiment$clean_text, sentiment)

df_sentiment_clean = df_sentiment %>%
  group_by(neighborhood, year) %>%
  unnest(sentiment) %>%
  summarise(score = mean(sentiment))

write.csv(df_sentiment_clean, "neighborhood_sentiment_scores.csv")


```



```{r, message=FALSE, warning=FALSE}

word.count <- function(words=c("really great good stuff bad")){
  require(quanteda)
  tok <- quanteda::tokens(words)
  count <- sum(tok[[1]]%in%tok[[1]])
  count = ifelse(is.na(count), 0, count)
  return (count)
}

df_clean$wordcount = lapply(df_clean$text, word.count)

df_wordcount = df_clean %>%
  group_by(neighborhood, year) %>%
  unnest(wordcount) %>%
  summarise(count = median(wordcount))

write.csv(df_wordcount, "wordcount_by_year.csv")

```


#